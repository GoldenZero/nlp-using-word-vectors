{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP using Word Vectors with Spacy\n",
    "\n",
    "This notebook will show you how to ustilise word vectors using spacy and how they can be used in creating and \"What to read next...\" system.\n",
    "\n",
    "[Spacy](https://spacy.io/) is a production grade open source NLP library that includes word vectors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK** : load the word vectors by running :\n",
    "\n",
    "```python\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "```\n",
    "\n",
    "You can see [here](https://spacy.io/models/en#en_core_web_lg) that this model contains 685,000 unique word vectors!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get comfortable with a single word vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK** : get the vector of any word by running:\n",
    "```python\n",
    "nlp('dog').vector\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -4.01760012e-01,   3.70570004e-01,   2.12810002e-02,\n",
       "        -3.41250002e-01,   4.95380014e-02,   2.94400007e-01,\n",
       "        -1.73759997e-01,  -2.79819995e-01,   6.76219985e-02,\n",
       "         2.16930008e+00,  -6.26909971e-01,   2.91060001e-01,\n",
       "        -6.72699988e-01,   2.33190000e-01,  -3.42640013e-01,\n",
       "         1.83109999e-01,   5.02260029e-01,   1.06889999e+00,\n",
       "         1.46980003e-01,  -4.52300012e-01,  -4.18269992e-01,\n",
       "        -1.59669995e-01,   2.67479986e-01,  -4.88669991e-01,\n",
       "         3.64620000e-01,  -4.34029996e-02,  -2.44739994e-01,\n",
       "        -4.17519987e-01,   8.90880004e-02,  -2.55519986e-01,\n",
       "        -5.56949973e-01,   1.22429997e-01,  -8.35260004e-02,\n",
       "         5.50949991e-01,   3.64100009e-01,   1.53610006e-01,\n",
       "         5.57380021e-01,  -9.07019973e-01,  -4.90979999e-02,\n",
       "         3.85800004e-01,   3.79999995e-01,   1.44250005e-01,\n",
       "        -2.72210002e-01,  -3.70160013e-01,  -1.29040003e-01,\n",
       "        -1.50849998e-01,  -3.80760014e-01,   4.95829992e-02,\n",
       "         1.27550006e-01,  -8.27879980e-02,   1.43390000e-01,\n",
       "         3.25370014e-01,   2.72260010e-01,   4.36320007e-01,\n",
       "        -3.17690015e-01,   7.94049978e-01,   2.65289992e-01,\n",
       "         1.01350002e-01,  -3.32789987e-01,   4.31169987e-01,\n",
       "         1.66869998e-01,   1.07290000e-01,   8.94180015e-02,\n",
       "         2.86350012e-01,   4.01169986e-01,  -3.92219990e-01,\n",
       "         4.52170014e-01,   1.35210007e-01,  -2.88780004e-01,\n",
       "        -2.28189994e-02,  -3.49750012e-01,  -2.29959995e-01,\n",
       "         2.02240005e-01,  -2.11769998e-01,   2.71840006e-01,\n",
       "         9.17029977e-02,  -2.06100002e-01,  -6.57580018e-01,\n",
       "         1.89490005e-01,  -2.67560005e-01,   9.26389992e-02,\n",
       "         4.33160007e-01,  -4.88680005e-01,  -3.83089989e-01,\n",
       "        -2.19099998e-01,  -4.41830009e-01,   9.80440021e-01,\n",
       "         6.74229980e-01,   8.40030015e-01,  -1.81690007e-01,\n",
       "         1.73850000e-01,   4.18480009e-01,   1.60980001e-01,\n",
       "        -1.04900002e-01,  -4.19649988e-01,  -3.56599987e-01,\n",
       "        -1.68369994e-01,  -6.34580016e-01,   3.84220004e-01,\n",
       "        -3.50430012e-01,   1.74860001e-01,   5.35279989e-01,\n",
       "         2.01429993e-01,   3.78770009e-02,   4.71049994e-01,\n",
       "        -4.43439990e-01,   1.68400005e-01,  -1.66850001e-01,\n",
       "        -2.40219995e-01,  -1.00769997e-01,   3.03339988e-01,\n",
       "         4.27300006e-01,   3.38030010e-01,  -4.34810013e-01,\n",
       "         1.13430001e-01,   6.19580001e-02,   6.18080013e-02,\n",
       "        -1.40070006e-01,   8.20180029e-02,  -3.91299985e-02,\n",
       "         5.14420010e-02,   2.87250012e-01,   5.80250025e-01,\n",
       "        -5.76409996e-01,  -3.46520007e-01,   1.01319999e-01,\n",
       "         1.44630000e-01,   1.15689998e-02,  -3.37009996e-01,\n",
       "        -1.75860003e-01,  -3.57239991e-01,  -2.14230001e-01,\n",
       "         1.14289997e-02,   4.76449996e-01,  -3.74629982e-02,\n",
       "        -2.94880003e-01,  -1.74649999e-01,   3.02549988e-01,\n",
       "         6.03169978e-01,  -6.67899996e-02,  -2.70499992e+00,\n",
       "        -7.03079998e-01,   4.05479997e-01,   6.28740013e-01,\n",
       "         6.30800009e-01,  -5.45130014e-01,  -9.61910002e-03,\n",
       "         2.65329987e-01,   2.33909994e-01,  -5.18859997e-02,\n",
       "        -6.57590013e-03,   1.85729992e-02,  -4.56930012e-01,\n",
       "        -7.03509971e-02,  -3.06210011e-01,  -1.40180001e-02,\n",
       "        -2.04080001e-01,   3.70999992e-01,  -3.23540002e-01,\n",
       "        -8.46459985e-01,   2.70920008e-01,  -1.19609997e-01,\n",
       "        -9.55760032e-02,  -6.04640007e-01,   4.24089991e-02,\n",
       "         2.46560007e-01,   3.84449996e-02,  -2.54670009e-02,\n",
       "        -9.29080024e-02,  -2.13560000e-01,   3.61200005e-01,\n",
       "         1.91130005e-02,   6.27409965e-02,  -1.30830005e-01,\n",
       "        -1.51460001e-03,   5.82379997e-01,  -1.89559996e-01,\n",
       "         7.81050026e-01,   1.04769999e-02,   1.09280002e+00,\n",
       "         1.01400003e-01,  -3.62480015e-01,  -1.19620003e-01,\n",
       "        -3.44619989e-01,  -5.57039976e-01,   2.57970005e-01,\n",
       "         3.33559990e-01,   3.31939995e-01,  -3.12979996e-01,\n",
       "        -7.55469978e-01,  -7.52900004e-01,  -9.30719972e-02,\n",
       "        -1.11730002e-01,  -5.72510004e-01,   1.66390002e-01,\n",
       "         6.35789990e-01,   2.40060002e-01,  -2.92109996e-01,\n",
       "         9.01820004e-01,   1.24250002e-01,  -5.77509999e-01,\n",
       "         4.79860008e-02,  -4.27480012e-01,   2.44460002e-01,\n",
       "         4.72319983e-02,   3.56940001e-01,   4.42409992e-01,\n",
       "        -2.30550006e-01,   6.60369992e-01,  -7.39829987e-03,\n",
       "        -3.78569990e-01,   2.27589995e-01,  -3.71380001e-01,\n",
       "         3.10550004e-01,  -7.21049979e-02,  -2.44900003e-01,\n",
       "        -3.97609994e-02,   5.36499977e-01,  -4.14779991e-01,\n",
       "         1.65629998e-01,   3.37069988e-01,   1.09200001e-01,\n",
       "         3.72189999e-01,  -5.57269990e-01,  -7.80600011e-01,\n",
       "         1.42509997e-01,  -3.58280003e-01,   4.16379988e-01,\n",
       "         2.14460000e-01,   1.84100002e-01,  -4.77039993e-01,\n",
       "        -2.20049992e-02,  -2.36340001e-01,  -2.28400007e-01,\n",
       "         3.47220004e-01,   2.36670002e-01,   7.42489994e-02,\n",
       "        -8.84160027e-02,   2.86179990e-01,  -4.69419986e-01,\n",
       "        -4.39139992e-01,  -2.64739990e-01,  -3.06899995e-01,\n",
       "        -1.52600005e-01,  -8.48700032e-02,   2.84099996e-01,\n",
       "        -1.84809998e-01,  -2.21220002e-01,  -1.11690000e-01,\n",
       "        -2.52410006e-02,   4.59679998e-02,   3.53429988e-02,\n",
       "         2.24669993e-01,   5.15559971e-01,  -6.51369977e-04,\n",
       "         9.95590016e-02,  -1.42150000e-01,   2.01360002e-01,\n",
       "         2.83340007e-01,  -2.87719995e-01,   3.77659984e-02,\n",
       "        -3.76080006e-01,  -1.16810001e-01,  -6.70199990e-01,\n",
       "        -4.62649986e-02,   3.87840003e-01,  -3.22949998e-02,\n",
       "        -5.42909987e-02,  -4.53839988e-01,   1.95519999e-01,\n",
       "        -2.94699997e-01,   8.50090027e-01,   1.03450000e-01,\n",
       "         9.70100015e-02,   1.13389999e-01,   3.95020008e-01,\n",
       "         5.90430014e-02,   2.19779998e-01,   1.88449994e-01,\n",
       "        -1.58910006e-01,  -1.03009999e-01,   3.31640005e-01,\n",
       "         6.14770018e-02,  -2.98480004e-01,   4.45100009e-01,\n",
       "         4.73289996e-01,   2.63119996e-01,  -1.84949994e-01,\n",
       "         1.46520004e-01,  -3.15099992e-02,   2.29080003e-02,\n",
       "        -2.59290010e-01,  -3.08620006e-01,   1.75449997e-03,\n",
       "        -1.89620003e-01,   5.47890007e-01,   3.11940014e-01,\n",
       "         2.46930003e-01,   2.99290001e-01,  -7.48609975e-02], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YORU CODE GOES HERE\n",
    "\n",
    "nlp('dog').vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks like a lot of numbers, view the number of dimensions by using the `.shape` on a vector:\n",
    "\n",
    "**the output should look like this**:\n",
    "\n",
    "```python\n",
    "(300,)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "\n",
    "nlp('dog').vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK** : lets visualise the vector values in a bar plot:\n",
    "\n",
    "```python\n",
    "plt.bar(range(NUMBER_OF_DIMENSIONS), YOUR_VECTOR)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "When you have done that, play around with different words to see how they differ on the bar plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndgBIhmAHgGQIdgBI5v8BzW3TYRAB5/MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116786470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "\n",
    "plt.bar(range(300), nlp('dog').vector)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's now do some word comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK** : Create a varible called `cat` and assign it the vector for `\"cat\"`, and create a varible called `dog` and assign it the vector for `\"dog\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "\n",
    "cat = nlp('cat').vector\n",
    "dog = nlp('dog').vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to compare vectors\n",
    "\n",
    "**HEADS UP**- Don't worry if your not comfortable with the following maths, You won't need to fully understand it to progress, it's just a bit of extra background knowledge 😎\n",
    "\n",
    "On of the most common ways of caparing vectors is using [Cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity)\n",
    "\n",
    "Cosine similarity is a measure focusing on the angle between 2 vectors, if the the angle is small -> the cosine will be high and therefore they are similare vectors, if the angle is large -> the cosine will be small and therefore : they are very different vectors: \n",
    "\n",
    "![cosine](images/cosine_similarity.png)\n",
    "\n",
    "http://blog.christianperone.com/2013/09/machine-learning-cosine-similarity-for-vector-space-models-part-iii/\n",
    "\n",
    "It's calulated withe the following equation :\n",
    "\n",
    "![cosine equation](images/cosine.svg)\n",
    "\n",
    "We can do this in raw numpy with the following code:\n",
    "\n",
    "```python\n",
    "np.dot(VECTOR_1, VECTOR_2) / (np.linalg.norm(VECTOR_1) * np.linalg.norm(VECTOR_2))\n",
    "```\n",
    "\n",
    "**TASK** : Calculate the cosine similarity between your `dog` vector and your `cat` vector:\n",
    "\n",
    "Your answer should be close to `0.801685`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80168533"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "\n",
    "np.dot(dog, cat) / (np.linalg.norm(dog) * np.linalg.norm(cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ofcourse there are libraries that can do this for your!\n",
    "\n",
    "**TASK** : import the `cosine` function from the `scipy` package with the following import statement:\n",
    "\n",
    "```python\n",
    "from scipy.spatial.distance import cosine\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK** : Calulate the similarity between the dog and cat vectors like before using the `cosine` funnction\n",
    "```python\n",
    "1 - cosine(VECTOR_1, VECTOR_2)\n",
    "```\n",
    "\n",
    "same as before, your answer should be close to 0.801685"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80168542871441517"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "\n",
    "1 - cosine(cat, dog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Even easier! Spacy has it built in!\n",
    "\n",
    "Spacy will do this for you using `.similarity` on a nlp object:\n",
    "\n",
    "```python\n",
    "nlp('car').similarity(nlp('bike'))\n",
    "```\n",
    "\n",
    "**TASK** : Get the similarity between `'dog'` and `'cat'` using spacy's `.similarity` function:\n",
    "\n",
    "same as before, your answer should be close to 0.801685"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80168538937325962"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "\n",
    "nlp('cat').similarity(nlp('dog'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a list of words, **TASK** : print out how similiar each word is to `'cat'` in order to help you find out which is the best replacement pet:\n",
    "\n",
    "Check the completed notebook if your get stuck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car 0.319075305665\n",
      "truck 0.29983729522\n",
      "dragon 0.450325221289\n",
      "data 0.104425093599\n",
      "horse 0.484733482248\n",
      "fish 0.418065352251\n",
      "lion 0.526543720526\n"
     ]
    }
   ],
   "source": [
    "words = ['car', 'truck', 'dragon', 'data', 'horse', 'fish' , 'lion']\n",
    "\n",
    "#YOUR CODE GOES HERE\n",
    "\n",
    "for word in words:\n",
    "    print(word, nlp('cat').similarity(nlp(word)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onwards to document vectors!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to generate a document vector is just to get the average word vector in that document.\n",
    "\n",
    "You can do this using the techniques you've learnt previously using standard python loops and simple numpy operations e.g adding vectors using `+` and dividing using `/`.\n",
    "\n",
    "**TASK** : Calculate the average word vector of the sentence below. (I've provided a few bits of code to help)\n",
    "\n",
    "The `.sum()` of the document vector should around `-0.8358`\n",
    "\n",
    "Check the completed noetbook if you get stuck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.835803670343\n"
     ]
    }
   ],
   "source": [
    "sentence = 'why is the cat on the boat'\n",
    "\n",
    "# numpy array with the dimensions (300,), filled with zeros\n",
    "total = np.zeros(300)\n",
    "\n",
    "# words from the text split into a list\n",
    "words = sentence.split(' ')\n",
    "\n",
    "# number of words I the sentence\n",
    "n = len(words)\n",
    "\n",
    "# the varible tha the average word vector should be stored in \n",
    "average = None\n",
    "\n",
    "\n",
    "# YOUR CODE GOES HERE\n",
    "\n",
    "for word in words:\n",
    "    word_vec = nlp(word).vector\n",
    "    total += word_vec\n",
    "\n",
    "average = total / n\n",
    "\n",
    "# YOUR CODE ENDS HERE\n",
    "\n",
    "\n",
    "print(average.sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How you can do the same thing a bit quicker:\n",
    "\n",
    "```python\n",
    "# use list comprehension to get the vectors for each word\n",
    "word_vector_list = [nlp(word).vector for word in sentence.split(' ')]\n",
    "\n",
    "# calculate the mean across each word\n",
    "average_word_vector = np.mean(word_vector_list, axis=0)\n",
    "\n",
    "# check that the sum is the same as the other way\n",
    "print(average_word_vector.sum())\n",
    "```\n",
    "\n",
    "**TASK** : Copy and past the above code to check it gets a similar result as the previous task (should around `-0.8358`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.835803\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "\n",
    "# use list comprehension to get the vectors for each word\n",
    "word_vector_list = [nlp(word).vector for word in sentence.split(' ')]\n",
    "\n",
    "# covert that list to a numpy array and calculate the mean across each word\n",
    "average_word_vector = np.mean(word_vector_list, axis=0)\n",
    "\n",
    "# check that the sum is the same as the other way\n",
    "print(average_word_vector.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy to the rescue! again!\n",
    "\n",
    "Spacy will already do this average word vector calculation for you:\n",
    "\n",
    "```python\n",
    "nlp('what ever you want to say').vector\n",
    "```\n",
    "\n",
    "**TASK** : Do this for the sentence you used previously and check the sum is similare (should around `-0.8358`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.83580327"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "\n",
    "nlp(sentence).vector.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like how you've already done it with words, find out which of the following sentences is most similar to the sentence `'why is my cat on the car'`:\n",
    "\n",
    "**TASK** : print out the similarity score for each sentence against the `sentence_to_compare` to help you see which one is most similar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "where did my dog go - 0.879428120233\n",
      "dude where's my car - 0.902923529769\n",
      "i've lost my cat in the car - 0.925151406861\n",
      "get that boat back - 0.820837202062\n",
      "find my cat - 0.863482748178\n",
      "why is my dog on the drugs - 0.928325851442\n"
     ]
    }
   ],
   "source": [
    "sentence_to_compare = 'why is my cat on the car'\n",
    "\n",
    "sentences = [\"where did my dog go\", \n",
    "             \"dude where's my car\",\n",
    "             \"i've lost my cat in the car\",\n",
    "             \"get that boat back\",\n",
    "             \"find my cat\",\n",
    "             \"why is my dog on the drugs\"]\n",
    "\n",
    "# YOURE CODE GOES HERE\n",
    "\n",
    "for sentence in sentences:\n",
    "    sim = nlp(sentence_to_compare).similarity(nlp(sentence))\n",
    "    print(sentence,'-', sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's improve our sentence similarity system by removing stop words i.e very common words that carry little meaning. \n",
    "\n",
    "Below we have created the function `remove_stop_words()` which will remove stop words from text passed to it e.g:\n",
    "\n",
    "```python\n",
    "remove_stop_words('why is my dog on the drugs')\n",
    ">> dog drugs\n",
    "```\n",
    "\n",
    "**TASK** : Using this function, do the same task as before (print out the similarity score for each sentence against the sentence_to_compare to help you see which one is most similar) but make sure you remove the stop words when your doing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "where did my dog go - 0.703443348496\n",
      "dude where's my car - 0.71713842303\n",
      "i've lost my cat in the car - 0.810616945171\n",
      "get that boat back - 0.461349352674\n",
      "find my cat - 0.788653348563\n",
      "why is my dog on the drugs - 0.605002483946\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    return ' '.join([word for word in text.split(' ') if word.lower() not in STOP_WORDS])\n",
    "\n",
    "# YOUR CODE GOES HERE\n",
    "\n",
    "for sentence in sentences:\n",
    "    sim = nlp(remove_stop_words(sentence_to_compare)).similarity(nlp(remove_stop_words(sentence)))\n",
    "    print(sentence,'-', sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alrighty let's visulise some word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
